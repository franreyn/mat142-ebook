<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<link rel="stylesheet" type="text/css" href="../../_utils/styles.css">
<script type="text/javascript" src="../../_utils/scripts.js" ></script> 
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" ></script>
<title>1.2 Sampling Methods</title>
</head>
<body>
<section class="ereader-display"> 
  <!-- START YOUR CONTENT--> 
  <!--===================-->
  <main>
    <h1>1.2 Sampling Methods</h1>
    <h2>1.2 Sampling Method</h2>
    <p>Upon completion of this section, you should be able to</p>
    <ul>
      <li>Identify different sampling methods</li>
      <li>Select appropriate sampling techniques</li>
      <li>Identify sources of bias</li>
    </ul>
    <hr>
    <h2>Introduction</h2>
    <p>As we mentioned in the previous section, the first thing we should do before conducting a survey is to identify the population that we want to study. Suppose we are hired by a politician to determine the amount of support they have among the electorate should they decide to run for another term. What population should we study? Every person in the district? Not every person is eligible to vote, and regardless of how strongly someone likes or dislikes the candidate, they don't have much to do with him or her being re-elected if they are not able to vote. </p>
    <p>What about eligible voters in the district? That might be better, but if someone is eligible to vote but does not register by the deadline, they won't have any say in the election either. What about registered voters? Many people are registered but choose not to vote. What about &quot;likely voters?&quot;</p>
    <p>This is the criteria used in many political polling, but it is sometimes difficult to define a &quot;likely voter.&quot; Is it someone who voted in the last election? In the last general election? In the last presidential election? Should we consider someone who just turned 18 a &quot;likely voter?&quot; They weren't eligible to vote in the past, so how do we judge the likelihood that they will vote in the next election?</p>
    <p>In November 1998 former professional wrestler Jesse &quot;The Body&quot; Ventura was elected governor of Minnesota. Up until right before the election, most polls showed he had little chance of winning. There were several contributing factors to the polls not reflecting the actual intent of the electorate: </p>
    <ul type="disc">
      <li>Ventura was running on a third-party ticket and most polling methods are better suited to a two-candidate race.</li>
      <li>Many respondents to polls may have been embarrassed to tell pollsters that they were planning to vote for a professional wrestler.</li>
      <li>The mere fact that the polls showed Ventura had little chance of winning might have prompted some people to vote for him in protest to send a message to the major-party candidates. </li>
    </ul>
    <p>But one of the major contributing factors was that Ventura recruited a substantial amount of support from young people, particularly college students, who had never voted before and who registered specifically to vote in the gubernatorial election.&nbsp; The polls did not deem these young people likely voters (since in most cases young people have a lower rate of voter registration and a turnout rate for elections) and so the polling samples were subject to <strong>sampling bias</strong>: they omitted a portion of the electorate that was weighted in favor of the winning candidate.&nbsp;</p>
    <div class="definition">
      <h4>Sampling bias</h4>
      <p>A sampling method is biased if it every member of the population does not have equal likelihood of being in the sample.&nbsp; </p>
    </div>
    <p>In 2016 Reuters reported "pollsters and statisticians gave Hillary Clinton odds of between 75 and 99 percent of winning the U.S. presidential election." In the end Clinton did win the popular vote, but not the election. </p>
    <div class="plainblock">
      <p>... president and vice president are not elected directly by citizens. Instead, they’re chosen by “electors” through a process called the Electoral College. From <a href="https://www.usa.gov/election" target="_blank" >https://www.usa.gov/election</a></p>
    </div>
    <p>So again we ask what happened? Like the Ventura case there were conditions where who the likely voter estimates was incorrect as well as some other factors that changed the outcome. From the American Association for Public Opinion Research (AAPOR):</p>
    <div class="plainblock">
      <p>"there was a strong correlation between education and presidential vote in key states. Voters with higher education levels were more likely to support Clinton. Furthermore, recent studies are clear that people with more formal education are significantly more likely to participate in surveys than those with less education. Many polls – especially at the state level – did not adjust their weights to correct for the over-representation of college graduates in their surveys, and the result was over-estimation of support for Clinton." From <a href="https://www-archive.aapor.org/education-resources/reports/an-evaluation-of-2016-election-polls-in-the-u-s.aspx" target="_blank" >AAPOR Report: An Evaluation of 2016 Election Polls in the U.S. </a></p>
    </div>
    <p>Does this mean all is not well with using Polls to help predict election results? The answer to that is no. The errors identified didn't show any major cause for concern as indicated at the annual conference of the American Association of Public Opinion Research (AAPOR).</p>
    <div class="plainblock">
      <p>Errors have happened enough in past elections to know that an upset was well within the realm of possibility in 2016. The Upshot model estimated that a polling misfire was about as likely as a baseball strikeout or a missed midrange field goal in football. It’s not pretty, but it happens and will happen again, and a team wouldn’t release a batter or a kicker because of a strikeout or a missed kick. From <a href="https://www.nytimes.com/2017/05/31/upshot/a-2016-review-why-key-state-polls-were-wrong-about-trump.html" target="_blank" >A 2016 Review: Why Key State Polls Were Wrong About Trump</a></p>
    </div>
    <p>What we need to do as consumers of data is understand the surveys and polls conducted cannot be 100% accurate. The data they provide are invaluable, but are also subject to be incorrect. In this section we will look at different forms of bias as well as different methods to conduct surveys in this section. This will hopefully give you a better understanding of what makes for a good survey design and what to watch out for in the results.</p>
    <h2>Samping Method</h2>
    <p>Identifying the population can be a difficult job, but how do we choose an appropriate sample from that population? Remember, although we would prefer to survey all members of the population, this is usually impractical unless the population is very small, so we choose a sample. There are many ways to sample a population, but there is one goal we need to keep in mind: we would like the sample to be <em>representative of the population</em>.</p>
    <p>Returning to our hypothetical job as a political pollster, we would not anticipate very accurate results if we drew all of our samples from among the customers at a Starbucks, nor would we expect that a sample drawn entirely from the membership list of the local gym would provide a useful picture of district-wide support for a candidate.</p>
    <p>One way to ensure that the sample has a reasonable chance of mirroring the population is to employ <em>randomness</em>. The most basic random method is simple random sampling.</p>
    <div class="definition">
      <h4>Simple random sample</h4>
      <p>A <strong>simple random sample</strong> is one in which each member of the population has an equal chance (probability) of being chosen</p>
    </div>
    <div class="example">
      <h3>Example 1</h3>
      <p>Which of the following scenarios represent a Simple Random Sample from the population?</p>
      <p><strong>Scenario 1</strong>: From all likely voters in the state, put each of their names on a piece of paper, toss the slips into a (very large) hat and draw 1000 slips out of the hat</p>
      <p><strong>Scenario 2</strong>: From all likely voters in the state, divide the voters by congressional district and for each district put each of their names on a piece of a paper, toss the slips into a (very large) hat and draw 100 slips out of the hat.</p>
      <p><strong>Scenario 3</strong>: From all likely voters in the state, randomly select five different letters from the alphabet. For each letter identify likely voters with a last name starting with that letter and put each of their names on a piece of a paper, toss the slips into a (very large) hat and draw 200 slips out of the hat.</p>
      <p><strong>Solution</strong></p>
      <p><strong>Scenario 1</strong>: This would be a simple random sample as every person in the population would have the same chance of being selected. This of course assumes that the names would be mixed and there was no impediment to selecting a slip from anywhere in the hat.</p>
      <p><strong>Scenario 2</strong>: Congressional districts in a state are supposed to be equal as possible (by law), but often can have population sizes that differ by up to 10% as the congressional districts are only drawn once every ten years. This would not be a simple random sample as not everyone has an equal chance of being in the survey (somebody living in the smallest district for the state has a higher chance of being selected compared to another living in the largest district).</p>
      <p><strong>Scenario 3</strong>: Although this seems like everyone would have the same chance initially once a letter is picked it changes the chance of someone to be selected depending on which group they belong to if those groups are not the same size. If there are 10,000 people in the group for letter "Q", but 200,000 for the group with letter "S", then anyone in group "S" will have a much lower chance to be in the survey. This would not be a simple random sample.</p>
    </div>
    <p>In practice, computers are better suited for this sort of endeavor than millions of slips of paper and extremely large headgear. Each person in the population is assigned a number and the computer then selects the individuals through a random process.</p>
    <p>It is always possible, however, that even a random sample might end up not being totally representative of the population. If we repeatedly take samples of 1000 people from among the population of likely voters in the state of Arizona, some of these samples might tend to have a slightly higher percentage of Democrats (or Republicans) than does the general population; some samples might include more older people and some samples might include more younger people; etc. In most cases, this <strong>sampling variability</strong> is not significant, but since we are including randomness there is a chance of a sample not being representative of the population.</p>
    <div class="definition">
      <h4>Sampling variability</h4>
      <p>The natural variation of samples is called <strong>sampling variability</strong>.</p>
    </div>
    <p>To help account for variability present in the population, pollsters might instead use a <strong>stratified sample</strong> where the strata (subgroup of the population) are made up with individuals with the same characteristics to ensure we are including a proportional representative from each characteristic.</p>
    <div class="definition">
      <h4>Stratified sampling</h4>
      <p>In <strong>stratified sampling</strong>, a population is divided into a number of subgroups (or strata). These subgroups would make up the whole population and no person can belong to more than one subgroup (this is also called partitioning the population). Next simple random samples are then taken from each subgroup with sample sizes proportional to the size of the subgroup in the population.</p>
    </div>
    <p>In the next example we will look at how stratified random sampling works.</p>
    <div class="example">
      <h3>Example 2</h3>
      <p>Suppose in a particular state that previous data indicated that the electorate was comprised of 39% Democrats, 37% Republicans and 24% independents. If a pollster was going to take a sample of 1000 people in that population determine the sample size from each of the strata identified (Democrat, Republican, and Independent).</p>
      <p><strong>Solution</strong></p>
      <p>In a sample of 1000 people we would want see the sample break down in to the same percentages as seen in the population. With stratified sampling this means 39% of the 1000 in the sample should be from the democrats, 37% of the 1000 from Republicans, and 24% of the 1000 from independents.</p>
      <p>Number of people to select from Democrats: 1000*0.39 = 390.<br>
        Number of people to select from Republicans: 1000*0.37 = 370.<br>
        Number of people to select from Independents: 1000*0.24 = 240.<br>
      </p>
    </div>
    <p>Stratified sampling can also be used to select a sample with people in desired age groups, a specified mix ratio of males and females, etc. By dividing the population into the groups (strata) we can ensure that individuals from those groups are included in the sample. What stratified sampling does not do is simplify the process as it is still a requirement to list out all the population for each strata and conduct a simple random sample from each of those groups. It adds an extra layer to the process as we need some way to identify from the population which category that sit in before doing the sampling.</p>
    <p>Is there another approach that gives us some similar characteristics to Stratified Sampling? Answer to that is yes. One variation on this technique is called <strong>quota sampling</strong>.</p>
    <p>In Quota sampling the population is divided into groups (strata), but the sampling methods from within the group is left open on how to proceed (does not require a simple random sampling technique) as well as the size for the quota (does not need to be proportional to what is in the population). If a poll lists quota sampling method as the technique it leaves room for concern as the way the sample was collected from the strata and the quota sizes may not be ideal to ensure the sample is representative of the population. This type of sampling does potentially save time and costs as the researcher determines how to select the subjects from each strata.</p>
    <div class="definition">
      <h4>Quota sampling</h4>
      <p><strong>In Quota sampling</strong>, a population is divided into a number of subgroups (or strata). A set number (quota) is defined to sample from each subgroup. The sampling method to pick the subjects is left to the researcher.</p>
    </div>
    <div class="example">
      <h3>Example 3</h3>
      <p>For each scenario determine if the sampling method used was stratified or quota. For both scenarios assume the population for the survey has the following demographics: 15% of the population is under 18, 45% of the population is between 18-40, 25% is between the 41-65, and the remaining is above 65. In both scenarios the sample size is 1000 people.</p>
      <p><strong>Scenario 1</strong>: A researcher calls people at random from each age group. They want 250 people from each of the identified age groups to be included in the sample.</p>
      <p><strong>Scenario 2</strong>: A researcher calls people at random from each age group. From the under 18 group 150 are called, from 28-40 a total of 450 are called, from 41-65 250 are called, and 150 are called that are 65 and older.</p>
      <p><strong>Solution</strong>s</p>
      <p><strong>Scenario 1</strong>. This looks similar to stratified random sampling, but is actually Quota Sampling. The number sampled from within each age group is not proportional to the population. By sampling 250 from each age group we have each age group representing 25% of the entire sample (250/1000*100%=25%). This is not equal to the given percentage of the population.</p>
      <p><strong>Scenario 2</strong>. This is stratified random sampling. The number sampled from within each age group is proportional to the population. 15% of the population was under 18 in the population and we see that 150 is 15% of 1000, so for this (and the other age group) the sample size as proportional to the population size.</p>
    </div>
    <p>The above example illustrates one of the drawbacks of quota sampling in that the proportions of each strata does not have to be equal to the population proportion. A good quota sampling would try to keep those proportions equal if they are known.</p>
    <p>Another sampling method is <strong>cluster sampling</strong>, in which the population is divided into groups, and one or more groups are randomly selected to be in the sample. In this case the groups that are formed should be as identical as possible (look like a mini version of the actual population itself). Otherwise by random variation we may end up selecting a group unlike the population as a whole and our data would be possibly skewed.</p>
    <div class="definition">
      <h4>Cluster sampling </h4>
      <p>In <strong>cluster sampling</strong>, the population is divided into subgroups (clusters) that are each similar to the population as a whole, and a set of subgroups are selected to be in the sample.</p>
    </div>
    <div class="example">
      <h3>Example 4</h3>
      <p>If the college wanted to survey students, since students are already divided into classes, they could randomly select 10 classes and give the survey to all the students in those classes. If they do this, what sampling method would they be using?</p>
      <p><strong>Solution</strong></p>
      <p>This would be cluster sampling. The students are broken into groups (classes) and then we take a sample of those groups (classes) and then survey all the students in the group (classes) that are selected.</p>
    </div>
    <p>In the example above we see a potential issue with cluster sampling if steps are not taken to ensure the clusters created are not similar to the population. In the case of randomly selecting 10 classes for the college there is a chance of randomly picking 10 100 level courses (freshman level classes) and having the results of the survey skewed.</p>
    <p>Another sampling method we often see is called <strong>systematic sampling</strong>.</p>
    <div class="definition">
      <h4>Systematic sampling</h4>
      <p>In <strong>systematic sampling</strong>, every <em>nth</em> member of the population is selected to be in the sample.</p>
    </div>
    <p>This method requires us to order the population (like assigning them a number and going in a numeric order).</p>
    <div class="example">
      <h3>Example 5</h3>
      <p>Identify which sampling method is used (Simple Random Sample, Systematic, Stratified, Quota, or Systematic):</p>
      <p><strong>Scenario 1</strong>: To select a sample at the college the researcher assigns each student a number starting at 1 and ending at 4500 (the total number of students) and then randomly chooses 100 numbers (students) to be part of the survey.</p>
      <p><strong>Scenario 2</strong>: To select a sample, a pollster calls every 100<sup>th</sup> name in the phone book.</p>
      <p><strong>Scenario 3</strong>: A pollster divides Tucson into zip codes and randomly surveys 25 people from each zip code.</p>
      <p><strong>Solution</strong>s</p>
      <p><strong>Scenario 1</strong>: This is a simple random sample. A random selection from the population where each person has the same chance of being selected.</p>
      <p><strong>Scenario 2</strong>: This is systematic sampling as we are somehow ordering the population and using a systematic approach to select every 100<sup>th</sup> person in that order. </p>
      <p><strong>Scenario 3</strong>: This is a Quota Sampling as the number selected from each group is not known to be proportional to the population.</p>
    </div>
    <p>Systematic sampling is not as random as a simple random sample (if your name is Albert Aardvark and your sister Alexis Aardvark is right after you in the phone book, there is no way you could both end up in the sample) but it can yield acceptable samples.<strong></strong></p>
    <p>Perhaps the worst types of sampling methods are <strong>convenience samples</strong> and <strong>voluntary response samples</strong>. </p>
    <div class="definition">
      <h4>Convenience sampling and voluntary response sampling</h4>
      <p><strong>Convenience sampling</strong> is samples chosen by selecting whoever is convenient.<br>
        <strong>Voluntary response sampling</strong> is allowing the sample to volunteer.</p>
    </div>
    <p>These two types of methods are very easy to conduct, but are prone to issues with the results. Have you ever been sitting in a class and your instructor surveys the class by asking if everyone understood the last slide on a presentation they were giving? Do you believe the responses by students gave an accurate representation of students understanding each time that happened? Probably not as some students may not want to speak up or the ones who did speak up and maybe said yes didn't represent the class as a whole.</p>
    <div class="example">
      <h3>Example 6</h3>
      <p>A pollster as stands on a street corner and interviews the first 100 people who agree to speak to them. What sampling method was used?</p>
      <p><strong>Solution</strong></p>
      <p>This is a convenience sample. The pollster is choosing members of the population that are easy to access. This sampling method should be avoided.</p>
    </div>
    <div class="example">
      <h3>Example 7</h3>
      <p>A website has a survey asking readers to give their opinion on a tax proposal. &nbsp;What sampling method was used?</p>
      <p><strong>Solution</strong></p>
      <p>This is a self-selected sample, or voluntary response sample, in which respondents volunteer to participate. The reason this is not just a convenience sample is that the respondent had to put effort into participating, so we call it a voluntary response sampling method instead.</p>
    </div>
    <p>Usually voluntary response samples are skewed towards people who have a particularly strong opinion about the subject of the survey or who just have way too much time on their hands and enjoy taking surveys.</p>
    <p> a. Every 4th person in the class was selected<br>
      b. A sample was selected to contain 25 men and 35 women<br>
      c. Viewers of a new show are asked to vote on the show&rsquo;s website<br>
      d. A website randomly selects 50 of their customers to send a satisfaction survey to<br>
      e. To survey voters in a town, a polling company randomly selects 10 city blocks, and interviews everyone who lives on those blocks.</p>
    <div class="tryitnow">
      <h3>Try it Now 1</h3>
      <p>A study is done to determine the average tuition that ASU undergraduate students pay per semester. Each student in the following samples are asked how much tuition he or she paid for the Fall semester. What is the type of sampling in each Scenario?</p>
      <p><strong>Scenario 1</strong>: A sample of 100 undergraduate ASU students is taken by organizing the students’ names by classification (freshman, sophomore, junior, or senior), and then selecting 25 students from each by assigning the students a number and randomly selecting 25 numbers.</p>
      <p><strong>Scenario 2</strong>: A random number generator is used to select a student from the alphabetical listing of all undergraduate students in the Fall semester. Starting with that student, every 50th student is chosen until 75 students are included in the sample.</p>
      <p><strong>Scenario 3</strong>: A completely random method is used to select 75 students. Each undergraduate student in the fall semester has the same chance of being chosen at any stage of the sampling process.</p>
      <p><strong>Scenario 4</strong>: The freshman, sophomore, junior, and senior years are numbered one, two, three, and four, respectively. A random number generator is used to pick two of those years. All students in those two years are in the sample.</p>
      <p><strong>Scenario 5</strong>: An administrative assistant is asked to stand in front of the library one Wednesday and to ask the first 100 undergraduate students he encounters what they paid for tuition the Fall semester. Those 100 students are the sample.</p>
      <h5 class="js-expandmore"> Hint 1 </h5>
      <div class="js-to-expand">
        <p><strong>Scenario 1</strong>: The population was first divided into different groups and then the selections were made. Were the amount selected from each group proportional to the numbers in the population (would it be safe to assume so)?</p>
        <p><strong>Scenario 2</strong>: The 75 selected is not what you should focus on here. The consistent selection of every 50th student identifies the sampling method.</p>
        <p><strong>Scenario 3</strong>: Each member in the population has the same chance of being selected and the population was not broken into any groups first.</p>
        <p><strong>Scenario 4</strong>: The population was divided into four groups and everyone in the selected groups were included in the sample. They did not take samples from each of the groups.</p>
        <p><strong>Scenario 5</strong>: Did the assistant have to put much effort to get the sample?</p>
      </div>
      <h5 class="js-expandmore"> Answer </h5>
      <div class="js-to-expand">
        <p><strong>Scenario 1</strong>: Quota Sampling (It is close to stratified random sampling, but it is probably not safe to assume that each class has same number of students.)</p>
        <p><strong>Scenario 2</strong>: Systematic Sampling</p>
        <p><strong>Scenario 3</strong>: Simple Random Sample</p>
        <p><strong>Scenario 4</strong>: Cluster Sampling</p>
        <p><strong>Scenario 5</strong>: Convenience Sampling</p>
      </div>
    </div>
    <h2>Bias: How to mess things up before you start</h2>
    <p><a href="http://youtu.be/GXAi06PiVsk" target="_blank" >Video Sampling Bias</a> (CC)</p>
    <p>There are number of ways that a study can be ruined before you even start collecting data. The first we have already explored &ndash; <strong>sampling </strong>or<strong> selection bias</strong>, which is when the sample is not representative of the population. One example of this is <strong>voluntary response bias</strong>, which is bias introduced by only collecting data from those who volunteer to participate. This is not the only potential source of bias.</p>
    <div class="definition">
      <h4>Sources of bias</h4>
      <p><strong>Sampling bias</strong> &ndash; when the sample is not representative of the population<br>
        <strong>Voluntary response bias</strong> &ndash; the sampling bias that often occurs when the sample is volunteers<br>
        <strong>Self-interest study</strong> &ndash; bias that can occur when the researchers have an interest in the outcome<br>
        <strong>Response bias</strong> &ndash; when the responder gives inaccurate responses for any reason<br>
        <strong>Perceived lack of anonymity</strong> &ndash; when the responder fears giving an honest answer might negatively affect them<br>
        <strong>Loaded questions</strong> &ndash; when the question wording influences the responses<br>
        <strong>Non-response bias</strong> &ndash; when people refusing to participate in the study can influence the validity of the outcome</p>
    </div>
    <p>In the examples that follow identify the largest source of bias that is present from the details given.</p>
    <div class="example">
      <h3>Example 8</h3>
      <p>Consider a recent study which found that chewing gum may raise math grades in teenagers<a href="#_ftn1" name="_ftnref1" title=""><sup>1</sup></a>. This study was conducted by the Wrigley Science Institute, a branch of the Wrigley chewing gum company. What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p> This is an example of a <strong>self-interest study</strong>; one in which the researches have a vested interest in the outcome of the study. While this does not necessarily ensure that the study was biased, it certainly suggests that we should subject the study to extra scrutiny. Not all self-interest studies are bias as many important pharmaceutical studies are funded by the companies who produce the drug.</p>
    </div>
    <div class="example">
      <h3>Example 9</h3>
      <p>A survey asks people &ldquo;when was the last time you visited your doctor?&rdquo; What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p>This might suffer from <strong>response bias</strong>, since many people might not remember exactly when they last saw a doctor and give inaccurate responses.</p>
    </div>
    <p>Sources of response bias may be innocent, such as bad memory, or as intentional as pressuring by the pollster. Response bias may be present even in very long surveys as the respondent gets fatigued and puts in any easy answer to just move it along as quickly as possible.</p>
    <div class="example">
      <h3>Example 10</h3>
      <p>A survey asks participants a question about their interactions with members of other races. What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p>Here, a <strong>perceived lack of anonymity</strong> could influence the outcome.&nbsp; The respondent might not want to be perceived as racist even if they are, and give an untruthful answer.&nbsp; </p>
    </div>
    <div class="example">
      <h3>Example 11</h3>
      <p>An employer puts out a survey asking their employees if they have a drug abuse problem and need treatment help. What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p><strong>Perceived lack of anonymity</strong>. Here, answering truthfully might have consequences; responses might not be accurate if the employees do not feel their responses are anonymous or fear retribution from their employer.</p>
    </div>
    <div class="example">
      <h3>Example 12</h3>
      <p>A survey asks &ldquo;do you support funding research of alternative energy sources to reduce our reliance on high-polluting fossil fuels?&rdquo;&nbsp; What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p>This is an example of a <strong>loaded </strong>or<strong> leading question</strong> &ndash; questions whose wording leads the respondent towards an answer. This question is leading the respondent with the negative environmental language in regards to fossil fuels.</p>
    </div>
    <p>Loaded questions can occur intentionally by pollsters with an agenda, or accidentally through poor question wording. Another concern is <strong>question order</strong>, where the order of questions changes the results.&nbsp; A psychology researcher (Swartz, Norbert) provides an example:</p>
    <div class="plainblock">
      <p>&ldquo;My favorite finding is this: we did a study where we asked students, 'How satisfied are you with your life? How often do you have a date?' The two answers were not statistically related - you would conclude that there is no relationship between dating frequency and life satisfaction. But when we reversed the order and asked, 'How often do you have a date? How satisfied are you with your life?' the statistical relationship was a strong one. You would now conclude that there is nothing as important in a student's life as dating frequency.&rdquo;</p>
    </div>
    <div class="example">
      <h3>Example 13</h3>
      <p>A telephone poll to asks the question &ldquo;Do you often have time to relax and read a book?&rdquo;, and 50% of the people called refused to answer the survey. What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p>It is unlikely that the results will be representative of the entire population.&nbsp; This is an example of <strong>non-response bias</strong>, introduced by people refusing to participate in a study or dropping out of an experiment.&nbsp; When people refuse to participate, we can no longer be so certain that our sample is representative of the population. </p>
    </div>
    <div class="example">
      <h3>Example 14</h3>
      <p>To determine how long it takes people to hit the brakes when an animal runs in the front of their car, 100 college students are recruited and put through a simulator. What potential source of bias should we be concerned about?</p>
      <p><strong>Solution</strong></p>
      <p>This is a case of sampling bias as our intended population was &quot;people&quot; in general and we limited our sampling to just college students.</p>
    </div>
    <div class="tryitnow">
      <h3>Try it Now 2</h3>
      <p>In each situation, identify a potential source of bias</p>
      <ol type="a">
        <li>A survey asks how many sexual partners a person has had in the last year</li>
        <li>A radio station asks readers to phone in their choice in a daily poll.</li>
        <li>A substitute teacher wants to know how students in the class did on their last test. The teacher asks the 10 students sitting in the front row to state their latest test score.</li>
        <li>High school students are asked if they have consumed alcohol in the last two weeks.</li>
        <li>The Beef Council releases a study stating that consuming red meat is poses little cardiovascular risk.</li>
        <li>A poll asks &ldquo;Do you support a new transportation tax, or would you prefer to see our public transportation system fall apart?&rdquo;</li>
      </ol>
      <h5 class="js-expandmore"> Hint 1 </h5>
      <div class="js-to-expand">
        <p>Use the definitions to help guide you.</p>
        <p><strong>Sampling bias</strong> &ndash; when the sample is not representative of the population<br>
          <strong>Voluntary response bias</strong> &ndash; the sampling bias that often occurs when the sample is volunteers<br>
          <strong>Self-interest study</strong> &ndash; bias that can occur when the researchers have an interest in the outcome<br>
          <strong>Response bias</strong> &ndash; when the responder gives inaccurate responses for any reason<br>
          <strong>Perceived lack of anonymity</strong> &ndash; when the responder fears giving an honest answer might negatively affect them<br>
          <strong>Loaded questions</strong> &ndash; when the question wording influences the responses<br>
          <strong>Non-response bias</strong> &ndash; when people refusing to participate in the study can influence the validity of the outcome</p>
      </div>
      <h5 class="js-expandmore"> Answer </h5>
      <div class="js-to-expand">
        <p>a. Response bias &ndash; historically, men are likely to over-report, and women are likely to under-report to this question. <br>
          b. Voluntary response bias &ndash; the sample is self-selected <br>
          c. Sampling bias &ndash; the sample may not be representative of the whole class <br>
          d. Lack of anonymity <br>
          e. Self-interest study <br>
          f. Loaded question</p>
      </div>
    </div>
    <h2>Exercises</h2><hr>
    <hr>
    <ol>
      <li>
      Determine the type of sampling used (quota, simple random, stratified, systematic, cluster, or convenience). <strong><br>
      <br>
      Scenario 1</strong>: A soccer coach selects six players from a group of boys aged eight to ten, seven players from a group of boys aged 11 to 12, and three players from a group of boys aged 13 to 14 to form a recreational soccer team.<br>
      <strong><br>
      Scenario 2</strong>: A pollster randomly selects five high tech companies with 50 or more employees and interviews all human resource personnel in those five different high tech companies. <br>
      <strong><br>
      Scenario 3</strong>: There are approximately 500 male and 500 female high school teachers in a school district. A high school educational researcher interviews 50 high school female teachers and 50 high school male teachers from within that district.<br>
      <strong><br>
      Scenario 4</strong>: A medical researcher interviews every third cancer patient from a list of cancer patients at a local hospital.<br>
      <strong><br>
      Scenario 5</strong>: A high school counselor uses a computer to generate 50 random numbers and then picks students whose names correspond to the numbers.<br>
      <strong><br>
      Scenario 6</strong>: A student interviews classmates in her algebra class to determine how many electronic devices a student owns.<br>
      <h5 class="js-expandmore"> Answer </h5>
      <div class="js-to-expand">
        <ol class="exerciseanswer">
          <li>Stratified</li>
          <li>Cluster.</li>
          <li>Quota sampling (although close to stratified we select quota sampling since we are not given information on how the 50 female/male teachers are selected)</li>
			 <li>Systematic</li>
          <li>Simple random</li>
          <li>Convenience</li>
        </ol>
      </div>
      </li>
      <li>Determine the type of sampling used (quota, simple random, stratified, systematic, cluster, or convenience).
        A high school principal polls 40 freshmen, 40 sophomores, 40 juniors, and 40 seniors regarding policy changes for after school activities. The freshman class is about 20% larger than the senior class while sophomore and junior classes are equal and about 10% less than the Freshman class.
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">Quota Sampling. Although this may look close to stratified random sampling the difference here is that the sample sizes are all equal, but the class level do not have the same number of students in each of them. This means the freshman class is over represented as a whole in the poll.</p>
        </div>
      </li>
      <li>In a study, the sample is chosen by writing everyone&rsquo;s name on a playing card, shuffling the deck, then choosing the top 20 cards.&nbsp; What is the sampling method?
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This is an example of a Simple Random Sample.</p>
        </div>
      </li>
      <li>In a study, the sample is chosen by separating all cars by size, and selecting 10 of each size grouping.&nbsp; What is the sampling method?
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This is an example of Quota Sampling.</p>
        </div>
      </li>
      <li>Pima Community College (PCC) has approximately 14,000 part-time students (the population). We are interested in the average amount of money a part-time student spends on books in the fall term. Asking all 14,000 students is an almost impossible task.
        <p>Suppose we take three different samples.</p>
        <p>First, we use convenience sampling and survey ten students from a first term organic chemistry class. Many of these students are taking first term calculus in addition to the organic chemistry class. The amount of money they spend on books is as follows:</p>
        <p>$128; $87; $173; $116; $130; $204; $147; $189; $93; $153</p>
        <p>The second sample is taken using a list of senior citizens who take P.E. classes and taking every fifth senior citizen on the list, for a total of ten senior citizens. They spend:</p>
        <p>$50; $40; $36; $15; $50; $100; $40; $53; $22; $22</p>
        <p>In the third sample we choose ten different part-time students from the disciplines of chemistry, business, English, psychology, sociology, history, nursing, physical education, art, and early childhood development. (We assume that these are the only disciplines in which part-time students at PCC are enrolled and that an equal number of part-time students are enrolled in each of the disciplines.) Each student is chosen using simple random sampling. The students spend the following amounts:</p>
        <p>$180; $50; $150; $85; $260; $75; $180; $200; $200; $150</p>
        <p>Do you think that any of these samples are representative of the entire part-time student population at PCC?</p>
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer"> It is unlikely any of the three were representative of the population as a whole. The first sample probably consists of science-oriented students. Besides the chemistry course, some of them are also taking first-term calculus. Books for these classes tend to be expensive. Most of these students are, more than likely, paying more than the average part-time student for their books. The second sample is a group of senior citizens who are, more than likely, taking courses for health and interest. The amount of money they spend on books is probably much less than the average part-time student. Both samples are biased. Also, in both cases, not all students have a chance to be in either sample. The third sample may unbiased, but a larger sample would be recommended to increase the likelihood that the sample will be close to representative of the population. However, for a biased sampling technique, even a large sample runs the risk of not being representative of the population. </p>
        </div>
      </li>
      <li> Identify the most relevant source of bias in this situation:&nbsp; A survey asks the following: Should the mall prohibit loud and annoying rock music in clothing stores catering to teenagers?
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This suffers from loaded or leading question bias</p>
        </div>
      </li>
      <li>Identify the most relevant source of bias in this situation:&nbsp; To determine opinions on voter support for a downtown renovation project, a surveyor randomly questions people working in downtown businesses.
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This suffers from sampling bias as not all voters may work in the downtown area.</p>
        </div>
      </li>
      <li>Identify the most relevant source of bias in this situation:&nbsp; A survey asks people to report their actual income and the income they reported on their IRS tax form.
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This question would likely suffer from a perceived lack of anonymity. People may not wish to give a truthful answer.</p>
        </div>
      </li>
      <li>Identify the most relevant source of bias in this situation:&nbsp; A survey randomly calls people from the phone book and asks them to answer a long series of questions. 70% of respondents refused to answer the survey.
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This may suffer from Non-response bias if they were told it was a long series of questions up front. If a person responds you also risk response bias if the list of questions is extremely long.</p>
        </div>
      </li>
      <li>Identify the most relevant source of bias in this situation: &nbsp;A survey asks the following: Should the death penalty be permitted if innocent people might die?
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This may suffer from loaded or leading question bias. The extra material at the end inputs extra information from the cons of the death penalty into the question and could influence a persons response.</p>
        </div>
      </li>
      <li>Identify the most relevant source of bias in this situation: &nbsp;A study seeks to investigate whether a new pain medication is safe to market to the public.&nbsp; They test by randomly selecting 300 men from a set of volunteers.
        <h5 class="js-expandmore"> Answer </h5>
        <div class="js-to-expand">
          <p class="exerciseanswer">This may suffer from voluntary response bias and sampling bias. The reason for sampling bias is if the population was to include woman they are not represented in the sample.</p>
        </div>
      </li>
    </ol>
    <hr />
    <div id="ftn1">
      <p>1. <a href="#_ftnref1" name="_ftn1" title=""> </a> Reuters.&nbsp; <a href="https://www.reuters.com/article/us-gum-learning/chewing-gum-may-raise-math-grades-in-teens-idUSTRE53L79320090422" target="_blank" >https://www.reuters.com/article/us-gum-learning/chewing-gum-may-raise-math-grades-in-teens-idUSTRE53L79320090422</a>. Retrieved 4/22/09</p>
    </div>
  </main>
  <footer>
    <div >
      <p class="text-center toggle-footnotes">[Show Attributions]</p>
      <div class="footnotes">
        <p>This page contains modified content by David Lippman Math in Society, <a href="http://www.opentextbookstore.com/mathinsociety/index.html" target="_blank"  rel="noopener">“Math In Society, 2nd Edition”</a></p>
        <p>This page contains modified content from <a href="https://chem.libretexts.org/@go/page/7082"  rel="noopener"> " Collecting Data" </a> by <a id="attr-author-link" href="https://irl.umsl.edu/oer/4/"  rel="noopener">Foster et al.</a>, <a href="https://libretexts.org/"  rel="noopener">LibreTexts</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"  rel="noopener"> CC BY-NC-SA </a>. </p>
        <p>This page contains modified content from <a href="https://openstax.org/books/introductory-statistics@25.17/pages/1-introduction" target="_blank"  rel="noopener"> "OpenStax Introductory Satistics: 1.2 Data, Sampling, and Variation in Data and Sampling" </a> by Barbara Illowsky, Susan Dean. CC BY 4.0. </p>
        <p>This page contains content by Robert Foth, Math Faculty, Pima Community College, 2021.</p>
      </div>
    </div>
  </footer>
  <!--=================--> 
  <!-- END YOUR CONTENT--> 
</section>
</body>
</html>
